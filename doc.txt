

--------------safetensor to quantized gguf
sudo apt update
sudo apt upgrade
sudo apt install git
sudo apt install make
sudo apt install libcurl4-gnutls-dev libexpat1-dev gettext libz-dev libssl-dev build-essential
git config --global user.email "meysamaghili533@gmai.com"
git config --global user.name "meysam"
ssh-keygen -t ed25519 -C "meysamaghili533@gmail.com"
eval "$(ssh-agent -s)" ssh-add ~/.ssh/id_ed25519
cat ~/.ssh/id_ed25519.pub
git clone git@github.com:ollama/ollama.git ollama
sudo apt install python3.10-venv
python3 -m venv .venv
source .venv/bin/activate
pip install -r /mnt/hgfs/github/llm/ollama/llm/llama.cpp/requirements.txt
sudo vmhgfs-fuse .host:/ /mnt/hgfs/ -o allow_other -o uid=1000
git submodule init
git submodule update llm/llama.cpp
make -C llm/llama.cpp quantize
/mnt/hgfs/github/llm/ollama/llm/llama.cpp/convert.py /mnt/hgfs/github/llm/AVA/AVA_repo/ --outfile /mnt/hgfs/github//llm/llmconv.gguf --outtype f32 --vocab-type bpe
llm/llama.cpp/quantize ../llmconv.gguf  ../llmconvquantized.gguf Q8_0


-----

ollama create AVA -f Modelfile
ollama run AVA "hello"